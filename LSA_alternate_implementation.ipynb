{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d11023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mONLINE SHOPPING SYSTEM:\u001b[0m \n",
      "\n",
      " * The purpose of this document is to provide a detailed outline of the requirements for the online shopping system .\n",
      "\n",
      " * This software requirement specification ( srs ) document outlines the requirements for the development of an online shopping system .\n",
      "\n",
      " * The online shopping system is a software system that allows customers to browse and purchase products online from the comfort of their own homes .\n",
      "\n",
      " * This document covers the functional and non-functional requirements for the online shopping system .\n",
      "\n",
      " * Software requirement specification of an online shopping system having the following sub topics introduction , purpose of this document , scope of this document , overview and general description .\n",
      "\n",
      " * This document will serve as a guide for the development team , ensuring that the final product meets the needs of both the business and the end-users .\n",
      "\n",
      " * The online shopping system is a web-based software application that enables customers to browse and purchase products online from various vendors .\n",
      "\n",
      " * The system is mainly for easy management of all the processes and operations regarding banking and transactions .\n",
      "\n",
      " * The system provides a convenient and user-friendly shopping experience for customers while enabling vendors to manage their product offerings , inventory , and orders efficiently .\n",
      "\n",
      " * This system will provide a centralized platform for customers to order and view products from the store thus eliminating the need of visiting the store .\n",
      "\n",
      "\u001b[1mThe online shopping system is a software system that allows customers to browse and purchase products online from the comfort of their own homes. This helps in eliminating the need for customers that have a busy schedule to be in store for purchasing and hence eliminating a scenario where customer does not get a particular product.:\u001b[0m \n",
      "\n",
      " * Overall , the interface of the online shopping system should be designed with user experience and usability in mind , with clear and intuitive navigation , high-quality product displays , and simple and secure checkout processes .\n",
      "\n",
      " * Overall , the performance requirements for an online shopping system should prioritize speed , reliability , security , and usability to ensure a positive user experience and maximize sales and revenue for the business .\n",
      "\n",
      " * The system should provide easy-to-use interfaces for managing user accounts , vendors , and reports , and help and support functionalities that enable users to resolve any issues they encounter .\n",
      "\n",
      " * Usability : the system should be easy to use and navigate , with clear and intuitive interfaces that allow users to quickly find what they are looking for and complete purchases with ease .\n",
      "\n",
      " * Vendor dashboard : the system should provide vendors with a dashboard that displays their product offerings , inventory levels , and order details , with easy-to-use interfaces for managing products , prices , and inventory .\n",
      "\n",
      " * User account management : the system should provide users with an easy way to create and manage their accounts , view their order history , and update their personal details .\n",
      "\n",
      " * Compatibility : the system should be compatible with a wide range of devices and browsers , to ensure that users can access the system from any device or platform .\n",
      "\n",
      " * The performance requirements for an online shopping system may vary depending on the specific needs and goals of the business , but some common performance requirements include.\n",
      "\n",
      " * Reports and analytics : the system should provide vendors with reports and analytics about sales , revenue , and customer behavior , with clear visualizations and easy-to-use interfaces .\n",
      "\n",
      " * Scalability : the system should be able to handle a growing number of users and transactions without sacrificing performance .\n",
      "\n",
      "\u001b[1mProblem Statement:                       :\u001b[0m \n",
      "\n",
      " * Overall , the online shopping system should provide a comprehensive set of features and functionalities that enable users to shop easily and vendors to manage their businesses effectively .\n",
      "\n",
      " * Shopping cart and checkout : the system should provide a shopping cart that displays the list of products added by users , including product images , descriptions , and prices .\n",
      "\n",
      " * Security : the system should be secure and protect customer information and payment details .\n",
      "\n",
      " * Functional requirements of online shopping system :.\n",
      "\n",
      " * Navigation and menus : the system should have clear and intuitive navigation and menus that enable users to find products and access different sections of the system easily .\n",
      "\n",
      " * Vendor management : the system should enable vendors to manage their products , prices , and inventory and view order details .\n",
      "\n",
      " * Usability : the system should be user-friendly and easy to use for applicants .\n",
      "\n",
      " * The following are some interface requirements of an online shopping system :.\n",
      "\n",
      " * Order tracking : the system should enable users to track the status of their orders and receive notifications about the order progress .\n",
      "\n",
      " * User interface : the system should have a user-friendly interface that enables users to browse products , search for items , add products to their cart , and complete purchases easily .\n",
      "\n",
      "Document 'sample.docx' does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PRASANNA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PRASANNA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from docx import Document\n",
    "from docx.shared import Pt, RGBColor\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define the path to the document\n",
    "doc_path = 'sample.docx'\n",
    "\n",
    "# Set the number of sentences for the summary\n",
    "num_sentences = 30 # Increase the number of sentences\n",
    "\n",
    "# Set the number of paragraphs per chunk\n",
    "paragraphs_per_chunk = 500\n",
    "\n",
    "# Define stopwords and punctuation\n",
    "stopwords_list = stopwords.words('english')\n",
    "punctuation_set = set(string.punctuation)\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "# Postprocess the summary content\n",
    "def postprocess_summary_content(content,heading):\n",
    "    # Capitalize the first letter of each sentence\n",
    "    sentences = sent_tokenize(content)\n",
    "    sentences = [sentence.capitalize() for sentence in sentences]\n",
    "\n",
    "    # Join the sentences back into the summary content\n",
    "    processed_content = ' '.join(sentences)\n",
    "\n",
    "    # Remove numbers at the beginning of sentences\n",
    "    #processed_content = re.sub(r\"^\\d+\\.\\s+--\\s*\", \"\", processed_content)\n",
    "\n",
    "    # Add punctuation and full stops\n",
    "    processed_content = processed_content.strip()\n",
    "    if not processed_content.endswith('.') and not content!=heading:\n",
    "        processed_content += '.'\n",
    "\n",
    "    return processed_content\n",
    "\n",
    "\n",
    "# Extract headings from the document\n",
    "# Extract headings from the document\n",
    "def extract_headings(document):\n",
    "    headings = []\n",
    "    previous_heading_level = 0\n",
    "    for paragraph in document.paragraphs:\n",
    "        if paragraph.style.name.startswith('Heading'):\n",
    "            # Consider the paragraph as a heading\n",
    "            headings.append(paragraph.text)\n",
    "            previous_heading_level = 0\n",
    "        elif paragraph.runs:\n",
    "            # Check if the paragraph has any runs (formatted text)\n",
    "            for run in paragraph.runs:\n",
    "                if run.bold or (run.font.size is not None and run.font.size > Pt(12)):\n",
    "                    # Consider the paragraph as a heading or subheading\n",
    "                    if previous_heading_level > 0:\n",
    "                        # Combine with the previous heading level\n",
    "                        headings[-1] += ' ' + paragraph.text\n",
    "                    else:\n",
    "                        # Append as a new heading\n",
    "                        headings.append(paragraph.text)\n",
    "                    previous_heading_level = 1\n",
    "                    break\n",
    "            else:\n",
    "                previous_heading_level = 0\n",
    "        else:\n",
    "            previous_heading_level = 0\n",
    "\n",
    "    return headings\n",
    "\n",
    "\n",
    "\n",
    "# Generate the summary for a chunk of text\n",
    "def generate_summary(headings, chunk, num_sentences):\n",
    "    # Preprocess the paragraphs in the chunk\n",
    "    if not chunk:\n",
    "        return {}\n",
    "    preprocessed_text = []\n",
    "    for paragraph in chunk:\n",
    "        preprocessed_paragraph = preprocess_text(paragraph)\n",
    "        preprocessed_text.extend(preprocessed_paragraph)\n",
    "\n",
    "    # Check if preprocessed_text is empty\n",
    "    if not preprocessed_text:\n",
    "        print(\"No text found for summarization.\")\n",
    "        return {}\n",
    "\n",
    "    # Create the TF-IDF matrix\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=None)  # Remove the stop_words parameter\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([' '.join(sentence) for sentence in preprocessed_text])\n",
    "\n",
    "    # Check if tfidf_matrix is empty\n",
    "    if tfidf_matrix.shape[0] == 0:\n",
    "        print(\"Insufficient data for summarization.\")\n",
    "        return {}\n",
    "\n",
    "    # Calculate the sentence importance scores\n",
    "    sentence_scores = calculate_sentence_scores(tfidf_matrix)\n",
    "\n",
    "    # Identify the important sentences\n",
    "    important_sentences = get_important_sentences(sentence_scores, num_sentences)\n",
    "\n",
    "    # Generate the summary with headings\n",
    "    summary_data = defaultdict(dict)\n",
    "    previous_heading = ''\n",
    "    used_sentences = set()\n",
    "    for i, sentence_id in enumerate(important_sentences):\n",
    "        heading_id = sentence_id // num_sentences\n",
    "        sentence_index = sentence_id % num_sentences\n",
    "        if heading_id < len(headings):\n",
    "            heading = headings[heading_id]\n",
    "            sentence = ' '.join(preprocessed_text[sentence_id])\n",
    "            sentence = sentence.capitalize()  # Capitalize the first letter\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence.endswith('.'):\n",
    "                sentence += '.'\n",
    "            if heading != previous_heading:\n",
    "                # Add two new lines if a new heading is encountered\n",
    "                summary_data[heading][-1] = '\\n\\n'\n",
    "                previous_heading = heading\n",
    "\n",
    "            # Check if the sentence has been used before\n",
    "            if sentence not in used_sentences:\n",
    "                used_sentences.add(sentence)\n",
    "                summary_data[heading][sentence_index] = sentence\n",
    "\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "# Calculate sentence importance scores using cosine similarity\n",
    "def calculate_sentence_scores(tfidf_matrix):\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    sentence_scores = similarity_matrix.sum(axis=1)\n",
    "\n",
    "    return sentence_scores\n",
    "\n",
    "\n",
    "# Identify the most important sentences based on scores\n",
    "def get_important_sentences(sentence_scores, num_sentences):\n",
    "    important_sentences = sentence_scores.argsort()[-num_sentences:][::-1]\n",
    "\n",
    "    return important_sentences\n",
    "\n",
    "\n",
    "# Load the document\n",
    "if os.path.exists(doc_path):\n",
    "    document = Document(doc_path)\n",
    "    headings = extract_headings(document)\n",
    "    paragraphs = [paragraph.text for paragraph in document.paragraphs]\n",
    "    num_chunks = len(paragraphs) // paragraphs_per_chunk\n",
    "    chunks = [paragraphs[i:i + paragraphs_per_chunk] for i in range(0, len(paragraphs), paragraphs_per_chunk)]\n",
    "\n",
    "    # Generate summaries for each chunk\n",
    "    summary_data = defaultdict(dict)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        summary_data_chunk = generate_summary(headings, chunk, num_sentences)\n",
    "        summary_data.update(summary_data_chunk)\n",
    "\n",
    "    # Post-process the summary content and print\n",
    "\n",
    "for heading, sentences in summary_data.items():\n",
    "    print(f\"\\033[1m{heading}:\\033[0m \\n\")\n",
    "    for sentence_index, sentence in sentences.items():\n",
    "        if sentence_index == -1:\n",
    "            continue\n",
    "        if sentence_index == 0:\n",
    "            sentence = sentence.lstrip(\"* \").rstrip(\".\")\n",
    "        print(f\" * {postprocess_summary_content(sentence, heading)}\\n\")\n",
    "\n",
    "else:\n",
    "    print(f\"Document '{doc_path}' does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752326e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
